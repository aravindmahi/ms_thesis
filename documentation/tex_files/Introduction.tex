\chapter{Introduction}
\markright{Aravindan Mahendiran \hfill Chapter 1. Introduction \hfill}
The last decade has seen a massive explosion of online data in multiple forms,
e.g.,  news articles, blogs and social media like Twitter, Facebook and MySpace.
Twitter, in particular, is a novel micro-blogging service launched in 2006.
Twitter users post messages called {\it tweets} on a public message board and these tweets are limited to 140 characters.
Originally the tweets were meant to be personal status updates but over the years these tweets have evolved to serve
multiple purposes.
Today, in addition to simple status updates, tweets can be URL references to websites, or even 
directed messages to specific individuals.
Due to the short nature of the messages users often combine multiple words into \emph{hashtags} to convey their views.
Therefore, such hashtags become the most important part of a tweet as often the entire essence of the tweet is captured in single hashtag.
They evolve over time and gain more traction as users adopt the popular ones.
This makes the language used in Twitter very different from other textual web content like blogs and articles.

Today twitter has grown so big\footnote{As of May 7,2013 twitter has 555 million active registered users with 135000 new users signing up every day and approximately 1 billion tweets created every 5 days.}
that it has come to be looked at as a treasure trove of mine-able data.
With official APIs that are open to public, the easy access to large volumes of data has piqued the interest 
of scientists in the data mining community.
Researchers have studied various real world phenomena like book sales~\cite{gruhl2005predictive}, box office earnings~\cite{asur2010predicting} and even stock prices~\cite{bollen2011twitter}, and have not only demonstrated strong 
correlations to the chatter on Twitter but were also able to make forecasts about future trends too.

An emerging trend is to study how online chatter can be used 
to model the social, economic or political landscape of a country.
Political leaders have started using Twitter as a channel to mobilize supporters for their ideologies.
For instance, during the 2008 US presidential election Barack Obama used social media and specifically 
Twitter extensively in his campaign. 
His victory established Twitter as a channel to garner support for a particular ideology be it political or otherwise.
Bollen et al. in their research ~\cite{bollen2011modeling} used a version of the well-established 
psychometric instrument- Profile of Mood States (POMS) to model the mood of Twitter traffic and found correlations to a number of social and economic events that occurred during the same time period. 
The results from this research encouraged more researchers to study and quantify political sentiment in 
social media and if possible even forecast elections.

Nevertheless, there is a constant debate among political scientists about whether Twitter can be 
used as a surrogate for political opinion of the masses.
Some believe Twitter indeed is an indicator of political opinions while others question the validity of such results.
In this work we aim to answer these questions by modeling online social groups through enhanced
vocabulary building and improving the performance of election prediction algorithms that use Twitter.
First, we review the current state-of-the-art in election forecasting using Twitter.

\section{Related Work}
We organize the literature review into three parts.
First we look at a selection of volume-based approaches to predict elections i.e., models that predict election 
results by merely counting the number of times a particular candidate is mentioned on Twitter.
Then we review more sophisticated approaches that model the demographics of an election to make more informed predictions.
Finally, we shall summarize a quite prevalent pessimistic view on such methodologies' capability to predict elections.
%Lastly we review Probabilistic Soft Logic, a framework we use to build a vocabulary dynamically.

\subsection{Volume based approaches}
In one of the most cited papers in this space~\cite{tumasjan2010predicting}, the authors claim that 
\emph{``The mere number of tweets reflect voter preferences and comes close to  traditional polls.."}
while predicting  the 2010 German federal election. % by counting candidate mentions on twitter.
They go on to strongly conclude that Twitter can indeed be a valid indicator of political opinion.
This was followed by ~\cite{o2010tweets,saez2011total,bermingham2011using,demartini2011analyzing} all of which use volume based approaches combined with sentiment analysis.
Both ~\cite{o2010tweets,bermingham2011using} fit a regression model to opinion polls with volume of mentions and sentiment as independent variables and the opinion polls as the dependent variable. 
They conclude that sentiment is a weak predictor compared to share of volume.
In general, the methodologies described in the above publications count the occurrence of certain handcrafted 
keywords and classify such tweets as positive or negative using a classifier trained on human annotated lexicons.
Some advanced sentiment classifiers also provide the likelihood that the
given sample of text belongs to an empirically defined psychological and structural category like 
anxiety, anger, and sadness.

\subsection{Profile Modeling}
More sophisticated approaches are presented in~\cite{livne2011party,conover2011predicting,diaz2012taking}. 
The authors either model the candidates or the voters in the elections rather than compute the aggregated sentiment of the mass.  
In~\cite{conover2011predicting} the authors build a support vector machine (SVM)
classifier trained on manually labeled tweets and classify users into `left' and `right' aligned.
Through latent semantic analysis (LSA),
they claim to have identified the hidden structure in the data that is strongly associated with 
users' political affiliations.
Using this information and how political information diffuses in a network, they show  an accuracy of 95\%  in 
predicting the political alignment of Twitter users.
Livne et al. in ~\cite{livne2011party} analyze the Twitter profiles of candidates who contested in 
the 2010 mid-term elections in the U.S. 
They identify topics specific to groups of candidates, split according to their known political orientations and use the features obtained as inputs to a regression model to predict the elections. 
In a similar technique Diaz-Aviles in~\cite{diaz2012taking} model the candidates by building an emotional vector for each candidate using the mentions of that candidate and sentiments associated with each mention learned using 
the NRC Emotion Lexicon (EmoLex). 
They then use such profiles learned to predict the rise and fall of a candidate's popularity.

In another thread of research, Mustafaraj et al. ~\cite{mustafaraj2011vocal} model the distribution of political content 
among Twitter users. 
They divide the users into two groups the ``vocal minority" and the ``silent majority". 
They observe that these two groups engage in different ways over social media.
The vocal minority aims to broaden the impact of tweets by re-tweeting and linking to other web content whereas 
the silent majority who tweet significantly lesser are more inclined to share their personal view points.
Though Mustafaraj et al. do not make any election forecasts, they make observations such as 
\emph{``Because of this difference between content generated by different groups, one should be 
aware of aggregating data and building models upon them, without verifying the underlying model 
that has generated the data."}.

\subsection{Flaws in current state of the art}
Of late there have been a lot of studies showing how such models that predict elections using social media feeds are flawed ~\cite{metaxas2011not,gayo2012wanted,gayo2011don,gayo2011limits}.
These publications not only list the obvious issues in using Twitter to predict elections but also detail recommendations on how to make such methodologies better.

Daniel Gayo-Avello surveys almost all the state-of-the-art approaches in predicting elections in his paper~\cite{gayo2012wanted} most of which have been detailed above.
According to him, post-hoc analysis of elections in retrospect must not count as valid predictions and that researchers 
must be wary of the \emph{file drawer} effect, i.e., the act of filing away negative results and publishing only the positive results.
His major points of argument against such models are:
\begin{itemize}
\item
Lack of explainability:
The models are tailor made to fit a particular election and that they need to be generic enough to reproduce similar results when run on other elections.
In particular Metaxas et al in ~\cite{metaxas2011not} state that any method claiming predictive power on the basis of Twitter data should be a clearly defined algorithm and should be ``explainable", i.e., black box approaches should be avoided.
\item
Vote modeling:
There is no predefined notion of ``vote" that has been used to predict the elections.
Most of the models aim to predict elections merely by counting the tweets related to a candidate.
\item
Self-selection bias:
Biases in Twitter are ignored. Twitter is not a representative sample of the electorate demographic as not every age, 
gender, or social group is represented.
Gayo-Avello
also notes that since people tweet on a voluntary basis, the data gathered is only by those who are politically active. 
Another point of contention is the credibility of tweets i.e., whether the tweets are rumors, campaign propaganda, 
or contain misleading information intended to maliciously attack a candidate's online popularity.
\item
Incumbency modeling:
Since in 2008 and 2010 , 91.6\% and 84\% of elections were won by the the incumbent candidate respectively, 
Gayo-Avello argues that incumbency should be used as the baseline measure rather than just chance.
He also notes that most of the methodologies are only slightly better than chance.
\item
Sentiment modeling:
Gayo-Avello states that
even though sentiment classifiers are a highly researched subspace of natural language processing (NLP), the 
accuracy of such methods are only slightly better than those of random classifiers. 
Further, these classifiers do not detect humor and sarcasm which in his opinion play a major role in political discussions.
\item
Absence of political opinions:
Lastly in ~\cite{gayo2011don} Gayo-Avello akin to ~\cite{mustafaraj2011vocal} states that abstaining from tweeting about politics can play even more important role than the ones mentioning the candidates and hence researches should also model this lack of chatter about a particular candidate or political party.
\end{itemize}

\section{Motivation}
Not withstanding the above drawbacks, a common element among all past (and future) methods
for forecasting elections using Twitter will be the
aspect of filtering tweets that match a vocabulary to obtain those that are pertinent to a given election.
Usually this is done by a process of querying the Twitter API for a set of keywords such as the names of 
the candidate and names/symbols of political parties contesting the elections.
Given that the language used on Twitter is completely different from the language in newspapers and magazines, this process will likely yield a very low recall.
%\aravind{Recall is used as a place holder. How to word this better?.}
%\naren{Recall is correct here. My only complaint is that you have no way of measuring the recall.}
For example, for the 2012 presidential election in Venezuela users preferred  the hashtags \emph{\#elmundocochavez} and \emph{\#hayuncamino} to show their support for Hugo Chavez and Henrique Capriles respectively.
Such hashtags are not known {\it a priori} and gain more traction and adoption closer to the election.
Querying just for ``chavez" or ``capriles" would result in discarding a huge bank of tweets that are indicative 
of a candidate's popularity.
Thus, it becomes vital that any methodology that predicts elections accounts for such memes that become popular 
during the time period leading up to the election.

In this work we build on earlier work in social group modeling~\cite{huang2012social} and address this issue by:
\begin{itemize}
\item
Designing and implementing a new dynamic query expansion algorithm using Probabilistic Soft Logic for vocabulary
building and expansion
\item
Showing how the vocabulary obtained from the Dynamic Query Expansion exercise improves the retrieval of relevant
tweets and improving the accuracy of prediction algorithms.
\item Conducting an exhaustive evaluation of our methodology across a set of national, state-level, and mayoral
elections in multiple countries of Latin America.
\end{itemize}

\section{Document Overview}
The rest of the document is organized as follows:
In the next chapter, we outline the Probabilistic Soft Logic (PSL) framework and how we take advantage 
of this domain specific language to build our dynamic query expansion algorithm.
In the third chapter, we detail two state-of-the-art algorithms used to predict elections and which can
benefit from our dynamic query expansion algorithm.
We then detail our experiments and present the results confirming our hypothesis in the fourth chapter.
In the final chapter, we make our final conclusions and present a road map for future work.
